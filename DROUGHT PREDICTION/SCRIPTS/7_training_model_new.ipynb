{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    confusion_matrix, balanced_accuracy_score, precision_recall_curve,\n",
    "    auc, make_scorer\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,  FunctionTransformer # MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from config import Config, Constant\n",
    "import os, sys\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_compile=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Station', 'Year', 'Month', 'Decade', 'v_wind_925', 'u_wind_850',\n",
       "       'u_wind_700', 'u_wind_200', 'eau_precipitable', 't_point_rosee',\n",
       "       'h_vol_sol_wat', 'anom_lef_dek', 'anom_nino_dek', 'Date',\n",
       "       'Label Secheresse', 'Saison_Pluie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(os.path.join(Config.DATASET_DIR,Config.DATA_1DEK))\n",
    "df_cleaned = df.dropna(subset=['Label Secheresse'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=['v_wind_925','u_wind_850','u_wind_700','u_wind_200','eau_precipitable','t_point_rosee','h_vol_sol_wat','anom_lef_dek','anom_nino_dek']\n",
    "#feature_rnn_dek=['v_wind_925','u_wind_850','u_wind_700','u_wind_200','eau_precipitable','t_point_rosee','h_vol_sol_wat','anom_lef_dek','anom_nino_dek','Label Secheresse']\n",
    "#feature_rnn_mon=['v_wind_925','u_wind_850','u_wind_700','u_wind_200','eau_precipitable','t_point_rosee','h_vol_sol_wat','anom_lef_mois','anom_nino_mois','Label Secheresse']\n",
    "\n",
    "feature_dek=['v_wind_925','u_wind_850','u_wind_700','u_wind_200','eau_precipitable','t_point_rosee','h_vol_sol_wat','anom_lef_dek','anom_nino_dek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Decade</th>\n",
       "      <th>v_wind_925</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_wind_700</th>\n",
       "      <th>u_wind_200</th>\n",
       "      <th>eau_precipitable</th>\n",
       "      <th>t_point_rosee</th>\n",
       "      <th>h_vol_sol_wat</th>\n",
       "      <th>anom_lef_dek</th>\n",
       "      <th>anom_nino_dek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label Secheresse</th>\n",
       "      <th>Saison_Pluie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.685185</td>\n",
       "      <td>-4.901044</td>\n",
       "      <td>-6.507310</td>\n",
       "      <td>24.359285</td>\n",
       "      <td>5.872143e-09</td>\n",
       "      <td>274.505384</td>\n",
       "      <td>0.177588</td>\n",
       "      <td>0.365944</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.627637</td>\n",
       "      <td>-1.549461</td>\n",
       "      <td>-1.188504</td>\n",
       "      <td>28.219953</td>\n",
       "      <td>1.950160e-08</td>\n",
       "      <td>274.479259</td>\n",
       "      <td>0.178358</td>\n",
       "      <td>0.232241</td>\n",
       "      <td>0.064786</td>\n",
       "      <td>1961-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.595885</td>\n",
       "      <td>-0.394695</td>\n",
       "      <td>2.207007</td>\n",
       "      <td>32.303318</td>\n",
       "      <td>-7.126785e-07</td>\n",
       "      <td>273.833101</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.668866</td>\n",
       "      <td>0.241058</td>\n",
       "      <td>1961-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.607470</td>\n",
       "      <td>-3.607335</td>\n",
       "      <td>3.229098</td>\n",
       "      <td>12.524779</td>\n",
       "      <td>-3.006926e-08</td>\n",
       "      <td>269.842157</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.866864</td>\n",
       "      <td>0.408497</td>\n",
       "      <td>1961-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.117176</td>\n",
       "      <td>-3.535849</td>\n",
       "      <td>3.110321</td>\n",
       "      <td>19.788904</td>\n",
       "      <td>-4.638627e-08</td>\n",
       "      <td>269.390330</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>1.098664</td>\n",
       "      <td>0.390542</td>\n",
       "      <td>1961-02-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Station    Year  Month  ...        Date  Label Secheresse  Saison_Pluie\n",
       "0  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-01               0.0         False\n",
       "1  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-02               0.0         False\n",
       "2  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-03               0.0         False\n",
       "3  Bobo_Dioulasso  1961.0    2.0  ...  1961-02-01               0.0         False\n",
       "4  Bobo_Dioulasso  1961.0    2.0  ...  1961-02-02               0.0         False\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un répertoire de sortie s'il n'existe pas déjà\n",
    "dir_resultat = Config.RESULT_DIR\n",
    "# Supprimer le dossier existant, y compris son contenu\n",
    "if os.path.exists(dir_resultat):\n",
    "    shutil.rmtree(dir_resultat)\n",
    "# Créer un nouveau répertoire de sortie\n",
    "os.makedirs(dir_resultat, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un répertoire de sortie s'il n'existe pas déjà\n",
    "dir_resultat_sel_var = Config.RESULT_DIR_SEL_VAR\n",
    "# Supprimer le dossier existant, y compris son contenu\n",
    "if os.path.exists(dir_resultat_sel_var):\n",
    "    shutil.rmtree(dir_resultat_sel_var)\n",
    "# Créer un nouveau répertoire de sortie\n",
    "os.makedirs(dir_resultat_sel_var, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Decade</th>\n",
       "      <th>v_wind_925</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_wind_700</th>\n",
       "      <th>u_wind_200</th>\n",
       "      <th>eau_precipitable</th>\n",
       "      <th>t_point_rosee</th>\n",
       "      <th>h_vol_sol_wat</th>\n",
       "      <th>anom_lef_dek</th>\n",
       "      <th>anom_nino_dek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label Secheresse</th>\n",
       "      <th>Saison_Pluie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.685185</td>\n",
       "      <td>-4.901044</td>\n",
       "      <td>-6.507310</td>\n",
       "      <td>24.359285</td>\n",
       "      <td>5.872143e-09</td>\n",
       "      <td>274.505384</td>\n",
       "      <td>0.177588</td>\n",
       "      <td>0.365944</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.627637</td>\n",
       "      <td>-1.549461</td>\n",
       "      <td>-1.188504</td>\n",
       "      <td>28.219953</td>\n",
       "      <td>1.950160e-08</td>\n",
       "      <td>274.479259</td>\n",
       "      <td>0.178358</td>\n",
       "      <td>0.232241</td>\n",
       "      <td>0.064786</td>\n",
       "      <td>1961-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.595885</td>\n",
       "      <td>-0.394695</td>\n",
       "      <td>2.207007</td>\n",
       "      <td>32.303318</td>\n",
       "      <td>-7.126785e-07</td>\n",
       "      <td>273.833101</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.668866</td>\n",
       "      <td>0.241058</td>\n",
       "      <td>1961-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.607470</td>\n",
       "      <td>-3.607335</td>\n",
       "      <td>3.229098</td>\n",
       "      <td>12.524779</td>\n",
       "      <td>-3.006926e-08</td>\n",
       "      <td>269.842157</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.866864</td>\n",
       "      <td>0.408497</td>\n",
       "      <td>1961-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bobo_Dioulasso</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.117176</td>\n",
       "      <td>-3.535849</td>\n",
       "      <td>3.110321</td>\n",
       "      <td>19.788904</td>\n",
       "      <td>-4.638627e-08</td>\n",
       "      <td>269.390330</td>\n",
       "      <td>0.173361</td>\n",
       "      <td>1.098664</td>\n",
       "      <td>0.390542</td>\n",
       "      <td>1961-02-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Station    Year  Month  ...        Date  Label Secheresse  Saison_Pluie\n",
       "0  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-01               0.0         False\n",
       "1  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-02               0.0         False\n",
       "2  Bobo_Dioulasso  1961.0    1.0  ...  1961-01-03               0.0         False\n",
       "3  Bobo_Dioulasso  1961.0    2.0  ...  1961-02-01               0.0         False\n",
       "4  Bobo_Dioulasso  1961.0    2.0  ...  1961-02-02               0.0         False\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation des fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction to_numeric_with_nan\n",
    "def to_numeric_with_nan(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return pd.NA  # Retourne une valeur manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_change(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    elif value == 0.0:\n",
    "        return 0\n",
    "    elif value == 1.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return value  # Si la valeur est différente de NaN, 0.0 et 1.0, la renvoyer telle quelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer les colonnes spécifiées\n",
    "def drop_columns(X, columns_to_drop):\n",
    "    return X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Colonnes à supprimer\n",
    "columns_to_drop = ['Station', 'Year', 'Month', 'Decade', 'Saison_Pluie','Date']\n",
    "#drop_columns_transformer = FunctionTransformer(drop_columns, kw_args={'columns_to_drop': columns_to_drop})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation de pipeline pour la gestion des variables numeriques et categorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer les colonnes spécifiées\n",
    "def drop_columns(X, columns_to_drop):\n",
    "    return X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Colonnes à supprimer\n",
    "columns_to_drop = ['Station', 'Year', 'Month', 'Decade', 'Saison_Pluie', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les features numériques (remplacez 'feature_dek' par votre liste réelle de colonnes numériques)\n",
    "numeric_features = feature_dek\n",
    "\n",
    "# Pipeline pour les features numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Stratified K-Fold cross-validation configuration\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline principal\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', SelectFromModel(RandomForestClassifier(random_state=42), threshold='median')),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres à tester pour GridSearch (ajoutez des hyperparamètres pour PCA si nécessaire)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Scorer basé sur le F1-Score\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Initialisation de GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rnf_train_evaluate(df, numeric_features, target_column, label_change, columns_to_drop, smote, skf, grid_search):\n",
    "def rnf_train_evaluate(df, numeric_features,spei, localite):\n",
    "    data = df.copy()\n",
    "\n",
    "    # Séparation des caractéristiques (X) et de la cible (y)\n",
    "    X = data.drop('Label Secheresse', axis=1)  # Remplacez 'Label Secheresse' par le nom de votre colonne cible\n",
    "    y = data['Label Secheresse'].apply(label_change)  # Assurez-vous que label_change est défini\n",
    "\n",
    "    # Drop columns before applying SMOTE\n",
    "    X = drop_columns(X, columns_to_drop)    \n",
    "\n",
    "    # Dictionnaire pour stocker les métriques pour chaque pli\n",
    "    metrics = {\n",
    "        'f1': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'roc_auc': [],\n",
    "        'balanced_acc': [],\n",
    "        'g_mean': [],\n",
    "        'pr_auc': []\n",
    "    }\n",
    "\n",
    "    # Liste pour stocker les trois principales caractéristiques pour chaque pli\n",
    "    top_features_list = []\n",
    "\n",
    "    # Validation croisée avec SMOTE et GridSearchCV\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Application de SMOTE sur les données d'entraînement uniquement\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Ajustement de GridSearchCV sur les données d'entraînement avec SMOTE\n",
    "        grid_search.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédiction sur les données de test avec le meilleur estimateur\n",
    "        y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "        y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calcul des différentes métriques\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred, pos_label=1))\n",
    "        metrics['precision'].append(precision_score(y_test, y_pred, pos_label=1))\n",
    "        metrics['recall'].append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        metrics['roc_auc'].append(roc_auc_score(y_test, y_pred_proba))\n",
    "        metrics['balanced_acc'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "        metrics['g_mean'].append(geometric_mean_score(y_test, y_pred))\n",
    "        \n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        metrics['pr_auc'].append(auc(recall_vals, precision_vals))\n",
    "        \n",
    "        # Extraction de l'importance des caractéristiques et sélection des 3 principales\n",
    "        feature_selector = grid_search.best_estimator_.named_steps['feature_selector']\n",
    "        model = feature_selector.estimator_\n",
    "        \n",
    "        importances = model.feature_importances_\n",
    "        important_indices = np.argsort(importances)[::-1][:3]\n",
    "        feature_names = X.columns\n",
    "        top_features = feature_names[important_indices].tolist()\n",
    "        \n",
    "        top_features_list.append(top_features)\n",
    "\n",
    "    # Calcul des moyennes et des écarts types des métriques\n",
    "    avg_metrics = {metric: f\"{localite}: {np.mean(values):.4f} ± {np.std(values):.4f}\" for metric, values in metrics.items()}\n",
    "    resultat_compile[f'Random forest_{localite}_{spei}']=avg_metrics\n",
    "\n",
    "    return avg_metrics, top_features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    }
   ],
   "source": [
    "grouped_data = df_cleaned.groupby('Station')\n",
    "for station, group_data in grouped_data:\n",
    "    rnf_train_evaluate(group_data, feature_dek,'1decade', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '1decade', 'extr', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A garder pour l'instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour supprimer les colonnes spécifiées\n",
    "def drop_columns(X, columns_to_drop):\n",
    "    return X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Colonnes à supprimer\n",
    "columns_to_drop = ['Station', 'Year', 'Month', 'Decade', 'Saison_Pluie', 'Date']\n",
    "\n",
    "# Définir les features numériques (remplacez 'feature_dek' par votre liste réelle de colonnes numériques)\n",
    "numeric_features = feature_dek\n",
    "\n",
    "# Pipeline pour les features numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Stratified K-Fold cross-validation configuration\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline principal\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', SelectFromModel(RandomForestClassifier(random_state=42), threshold='median')),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Paramètres à tester pour GridSearch (ajoutez des hyperparamètres pour PCA si nécessaire)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Scorer basé sur le F1-Score\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# Initialisation de GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Example data loading\n",
    "data = df_cleaned.copy()  # Remplacez avec vos données réelles\n",
    "data = data[data['Station'] == 'Gaoua']\n",
    "\n",
    "X = data.drop('Label Secheresse', axis=1)  # Remplacez 'Label Secheresse' par le nom de votre colonne cible\n",
    "y = data['Label Secheresse'].apply(label_change)  # Assurez-vous que label_change est défini\n",
    "\n",
    "# Drop columns before applying SMOTE\n",
    "X = drop_columns(X, columns_to_drop)\n",
    "\n",
    "# Store metrics for each fold\n",
    "metrics = {\n",
    "    'f1': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'roc_auc': [],\n",
    "    'balanced_acc': [],\n",
    "    'g_mean': [],\n",
    "    'pr_auc': []\n",
    "}\n",
    "\n",
    "# List to store the top 3 features for each fold\n",
    "top_features_list = []\n",
    "\n",
    "# Cross-validation with SMOTE and GridSearchCV\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE on the training data only\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Fit GridSearchCV on the SMOTE-applied training data\n",
    "    grid_search.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on the test data using the best estimator\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the different metrics\n",
    "    metrics['f1'].append(f1_score(y_test, y_pred, pos_label=1))\n",
    "    metrics['precision'].append(precision_score(y_test, y_pred, pos_label=1))\n",
    "    metrics['recall'].append(recall_score(y_test, y_pred, pos_label=1))\n",
    "    metrics['roc_auc'].append(roc_auc_score(y_test, y_pred_proba))\n",
    "    metrics['balanced_acc'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "    metrics['g_mean'].append(geometric_mean_score(y_test, y_pred))\n",
    "    \n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    metrics['pr_auc'].append(auc(recall_vals, precision_vals))\n",
    "    \n",
    "    # Extract the feature importance and top 3 features\n",
    "    feature_selector = grid_search.best_estimator_.named_steps['feature_selector']\n",
    "    model = feature_selector.estimator_\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    important_indices = np.argsort(importances)[::-1][:3]\n",
    "    feature_names = X.columns\n",
    "    top_features = feature_names[important_indices].tolist()\n",
    "    \n",
    "    top_features_list.append(top_features)\n",
    "\n",
    "# Displaying the average metrics across folds\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"Average {metric}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# Display the top 3 features from each fold\n",
    "print(\"Top 3 features in each fold:\")\n",
    "for fold, top_features in enumerate(top_features_list, 1):\n",
    "    print(f\"Fold {fold}: {top_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(X_train, y_train, X_valid, y_valid, X_test, y_test, spei, type_sec, localite):\n",
    "    input_shape = X_train[0].shape  # La forme d'entrée est déterminée par les données d'entraînement\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.LSTM(64, input_shape=input_shape),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Couche de sortie avec une seule unité et activation sigmoid pour la classification binaire\n",
    "    ])\n",
    "\n",
    "    # Compilez le modèle avec la perte et l'optimiseur spécifiés\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "    # Évaluez le modèle sur les données de test\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)  # Convertir les probabilités en classes binaires (0 ou 1)\n",
    "\n",
    "    # Calculez les métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Calculez le Mean Squared Error (MSE) et le Mean Absolute Error (MAE)\n",
    "    #mse = tf.keras.losses.mean_squared_error(y_test, y_pred_proba).numpy()\n",
    "    #mae = tf.keras.losses.mean_absolute_error(y_test, y_pred_proba).numpy()\n",
    "\n",
    "\n",
    "    resultat_compile[f'RNN_{localite}_{spei}_{type_sec}'] = {\n",
    "        'Mean Accuracy': round(np.mean([accuracy]), 3),\n",
    "        'Precision': round(precision, 3),\n",
    "        'Recall': round(recall, 3),\n",
    "        'F1 Score': round(f1, 3),\n",
    "        'ROC AUC': round(roc_auc, 3),\n",
    "        #'loss': round(loss, 3),\n",
    "        #'mse': round(np.mean([mse]), 3),\n",
    "        #'mae': round(np.mean([mae]), 3)\n",
    "    }\n",
    "    columns = ['Algo', 'Spei', 'Type_Sec', 'Station', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "\n",
    "    # Création du DataFrame avec des colonnes vides\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    metrics_obtenu = ['RNN', spei, type_sec, localite, np.mean([accuracy]), round(precision, 3), round(recall, 3),\n",
    "                      round(f1, 3), round(roc_auc, 3)]\n",
    "    # Ajout d'une nouvelle ligne au DataFrame\n",
    "    df.loc[len(df)] = metrics_obtenu\n",
    "    result_file_csv = os.path.join(dir_resultat, f'rnn_{spei}_{type_sec}_{localite}.csv')\n",
    "    result_file_excel = os.path.join(dir_resultat, f'rnn_{spei}_{type_sec}_{localite}.xlsx')\n",
    "\n",
    "    df.to_csv(result_file_csv, index=False)\n",
    "    df.to_excel(result_file_excel, index=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_rnn(df_data, feature_columns, time_columns, target_column, sequence_length, test_size=0.2, valid_size=0.5):\n",
    "    dataframe=df_data.copy()\n",
    "    # Étape 1 : Triez par la colonne temporelle\n",
    "    #dataframe.sort_values(by=time_columns [ 'Station',time_columns], ascending=[True, True], inplace=True)\n",
    "    if 'Decade' in dataframe.columns:\n",
    "        dataframe.sort_values(by=[ \"Year\", \"Month\", \"Decade\"], ascending=[True, True, True], inplace=True)\n",
    "    else:\n",
    "        dataframe.sort_values(by=[\"Year\", \"Month\"], ascending=[True, True], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Étape 2 : Sélection des caractéristiques et de la cible\n",
    "    features = feature_columns\n",
    "    target = target_column\n",
    "    dataframe[target]=dataframe[target].astype(int)\n",
    "\n",
    "    # Étape 3 : Création de séquences temporelles\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(len(dataframe) - sequence_length):\n",
    "        X.append(dataframe[features].values[i:i+sequence_length])\n",
    "        y.append(dataframe[target].values[i+sequence_length])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Aplatir les données\n",
    "    X = X.reshape(X.shape[0], -1)  # Aplatissement en 2D\n",
    "\n",
    "    # Étape 4 : Normalisation\n",
    "    scaler = StandardScaler()  #MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Étape 5 : Division des données\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=valid_size, shuffle=False)\n",
    "\n",
    "    # Étape 6 : Préparation des données pour le modèle RNN\n",
    "    X_train = X_train.reshape(X_train.shape[0], sequence_length, len(features))\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], sequence_length, len(features))\n",
    "    X_test = X_test.reshape(X_test.shape[0], sequence_length, len(features))\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRAINEMENT SUR LES DONNNEES DECADAIRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_1dek=load_data_dek(str(Config.DATASET_DIR) + '/' + str(Config.DATA_1DEK))\n",
    "data_1dek=load_data_dek(os.path.join(Config.DATASET_DIR,Config.DATA_1DEK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1dek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1dek['Label Secheresse'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '1decade', 'Sev_Extr', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '1decade', 'extr', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ext_1dek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    print(f\"Processing station: {station}\")\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(group_data, feature_columns=feature_rnn_dek, time_columns=[\"Year\", \"Month\", \"Decade\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train, X_valid, y_valid, X_test, y_test, '1decade', 'extr', station)\n",
    "    print(f\"Processing complete for station: {station}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sev_1dek=load_data_dek(str(Config.DATASET_DIR) + '/' + str(Config.DATA_1DEK_SEV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '1decade', 'sev', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '1decade', 'sev', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1dek.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_sev_1dek, feature_columns=feature_rnn_dek,time_columns=[\"Year\", \"Month\", \"Decade\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'1decade','sev',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRAINEMENT SPEI 1-MOIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ext_1mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_1MON_EXTR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '1mois', 'extr', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '1mois', 'extr', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_ext_1mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'1mois','extr',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sev_1mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_1MON_SEV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '1mois', 'sev', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '1mois', 'sev', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_1mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_sev_1mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'1mois','sev',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRAINEMENT SPEI 3-MOIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_ext_3mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_3MON_EXTR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '3mois', 'extr', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '3mois', 'extr', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_ext_3mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'3mois','extr',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sev_3mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_3MON_SEV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '3mois', 'sev', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '3mois', 'sev', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_3mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_sev_3mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'3mois','sev',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRAINEMENT SPEI 6-MOIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_ext_6mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_6MON_EXTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ext_6mois.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '6mois', 'extr', station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '6mois', 'extr', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ext_6mois.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_ext_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_ext_6mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'6mois','extr',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sev_6mois=load_data_mon(str(Config.DATASET_DIR) + '/' + str(Config.DATA_6MON_SEV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandonForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_sev_6mois=train_and_evaluate_model_ranf(data_sev_6mois)\n",
    "grouped_data = data_sev_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_model_ranf(group_data, '6mois', 'sev', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    train_and_evaluate_boost(group_data, '6mois', 'sev', station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data_sev_6mois.groupby('Station')\n",
    "\n",
    "# Parcourez chaque groupe et appliquez la fonction\n",
    "for station, group_data in grouped_data:\n",
    "    #data_by_st = group_data.drop(['station'], axis=1)  # Assurez-vous de supprimer la colonne 'station' si elle ne fait pas partie de vos fonctionnalités\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_data_for_rnn(data_sev_6mois, feature_columns=feature_rnn_mon,time_columns=[\"Year\", \"Month\"], target_column=\"Label Secheresse\", sequence_length=5)\n",
    "    create_rnn_model(X_train, y_train,X_valid, y_valid,X_test, y_test,'6mois','sev',station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRAINEMENT SPEI 1-MOIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(resultat_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./resultat.csv')\n",
    "result.to_excel('./resultat.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
